"""äº§å“çº§åˆ«ç«¯åˆ°ç«¯æµ‹è¯•è¿è¡Œå™¨

æ‰§è¡Œproduct-levelæµ‹è¯•é›†ï¼Œæ”¯æŒproduct_lookupå’Œsearch_policy_clauseæµ‹è¯•ã€‚
"""
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.mcp_server.tools.search_policy_clause import SearchPolicyClauseTool
from src.mcp_server.product_lookup import lookup_product
from src.common.logging import setup_logging

setup_logging()
logger = logging.getLogger(__name__)

class ProductLevelTestResult:
    """æµ‹è¯•ç»“æœ"""
    def __init__(self, test_case: Dict[str, Any]):
        self.test_id = test_case['id']
        self.category = test_case['category']
        self.question = test_case['question']
        self.product_name = test_case.get('product_name')
        self.company = test_case.get('company')
        self.expected_doc_type = test_case.get('expected_doc_type')
        
        # ç»“æœ
        self.status = "æœªæ‰§è¡Œ"
        self.response = []
        self.error = None
        self.execution_time = 0.0
        self.doc_type_correct = None  # ä»…ç”¨äºrate_tableæµ‹è¯•
        
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "test_id": self.test_id,
            "category": self.category,
            "question": self.question,
            "product_name": self.product_name,
            "status": self.status,
            "response_count": len(self.response),
            "execution_time_ms": round(self.execution_time * 1000, 2),
            "doc_type_correct": self.doc_type_correct,
            "error": self.error
        }

class ProductLevelTestRunner:
    """äº§å“çº§åˆ«æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, test_set_path: str):
        self.test_set_path = Path(test_set_path)
        self.test_data = self._load_test_set()
        self.results: List[ProductLevelTestResult] = []
        self.search_tool = SearchPolicyClauseTool()
        
    def _load_test_set(self) -> Dict[str, Any]:
        """åŠ è½½æµ‹è¯•é›†"""
        with open(self.test_set_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        total = len(self.test_data['test_cases'])
        logger.info(f"å¼€å§‹æ‰§è¡Œ{total}ä¸ªäº§å“çº§åˆ«æµ‹è¯•ç”¨ä¾‹...")
        
        for i, test_case in enumerate(self.test_data['test_cases'], 1):
            logger.info(f"[{i}/{total}] æ‰§è¡Œ: {test_case['id']} - {test_case['question']}")
            result = self._run_single_test(test_case)
            self.results.append(result)
            
        logger.info("æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œå®Œæˆ")
    
    def _run_single_test(self, test_case: Dict[str, Any]) -> ProductLevelTestResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        result = ProductLevelTestResult(test_case)
        category = test_case['category']
        
        try:
            import time
            start_time = time.time()
            
            if category == 'product_lookup':
                # äº§å“æŸ¥è¯¢æµ‹è¯•
                response = lookup_product(
                    product_name=test_case['question'],
                    company=test_case.get('company')
                )
                result.response = response if isinstance(response, list) else [response]
                result.status = "é€šè¿‡" if len(result.response) > 0 else "å¤±è´¥"
                
            else:
                # æ¡æ¬¾æŸ¥è¯¢æµ‹è¯• - å¿…é¡»æä¾›product_name
                if not test_case.get('product_name'):
                    raise ValueError(f"æµ‹è¯•ç”¨ä¾‹{test_case['id']}ç¼ºå°‘product_nameå‚æ•°")
                
                response = self.search_tool.run(
                    query=test_case['question'],
                    product_name=test_case['product_name'],
                    company=test_case.get('company'),
                    n_results=5,
                    min_similarity=test_case.get('min_similarity', 0.3)
                )
                result.response = response
                
                # åˆ¤æ–­æˆåŠŸ/å¤±è´¥
                if not response:
                    result.status = "å¤±è´¥"
                    result.error = "æœªè¿”å›ç»“æœ"
                else:
                    # ç‰¹æ®Šåˆ¤æ–­: è´¹ç‡è¡¨æµ‹è¯•å¿…é¡»æ£€æŸ¥doc_type
                    if category == 'rate_table_query':
                        top1_doc_type = response[0].doc_type if hasattr(response[0], 'doc_type') else None
                        result.doc_type_correct = (top1_doc_type == test_case['expected_doc_type'])
                        result.status = "é€šè¿‡" if result.doc_type_correct else "å¤±è´¥"
                    else:
                        # å…¶ä»–æµ‹è¯•: åªè¦æœ‰ç»“æœä¸”ç›¸ä¼¼åº¦>=é˜ˆå€¼å°±ç®—é€šè¿‡
                        top1_similarity = response[0].similarity_score if response else 0
                        result.status = "é€šè¿‡" if top1_similarity >= test_case.get('min_similarity', 0.3) else "å¤±è´¥"
            
            result.execution_time = time.time() - start_time
            
        except Exception as e:
            result.status = "é”™è¯¯"
            result.error = str(e)
            logger.error(f"æµ‹è¯•ç”¨ä¾‹ {test_case['id']} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        
        return result
    
    def generate_detailed_report(self, output_path: str):
        """ç”Ÿæˆè¯¦ç»†JSONæŠ¥å‘Š"""
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        stats_by_category = {}
        for result in self.results:
            cat = result.category
            if cat not in stats_by_category:
                stats_by_category[cat] = {"total": 0, "passed": 0, "failed": 0, "error": 0}
            stats_by_category[cat]["total"] += 1
            if result.status == "é€šè¿‡":
                stats_by_category[cat]["passed"] += 1
            elif result.status == "å¤±è´¥":
                stats_by_category[cat]["failed"] += 1
            else:
                stats_by_category[cat]["error"] += 1
        
        # è®¡ç®—é€šè¿‡ç‡
        for stats in stats_by_category.values():
            stats['pass_rate'] = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0
        
        report = {
            "test_set_name": self.test_data['name'],
            "test_set_version": self.test_data['version'],
            "total_count": len(self.results),
            "execution_time": datetime.now().isoformat(),
            "summary": {
                "total": len(self.results),
                "passed": sum(1 for r in self.results if r.status == "é€šè¿‡"),
                "failed": sum(1 for r in self.results if r.status == "å¤±è´¥"),
                "error": sum(1 for r in self.results if r.status == "é”™è¯¯"),
                "pass_rate": 0,
                "by_category": stats_by_category
            },
            "detailed_results": [r.to_dict() for r in self.results]
        }
        
        # è®¡ç®—æ€»é€šè¿‡ç‡
        report["summary"]["pass_rate"] = (
            report["summary"]["passed"] / report["summary"]["total"] * 100
            if report["summary"]["total"] > 0 else 0
        )
        
        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return report
    
    def generate_markdown_report(self, output_path: str):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        lines = ["# äº§å“çº§åˆ«ç«¯åˆ°ç«¯æµ‹è¯•æŠ¥å‘Š\n"]
        lines.append(f"**æµ‹è¯•é›†**: {self.test_data['name']}\n")
        lines.append(f"**æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        lines.append(f"**æµ‹è¯•ç”¨ä¾‹æ€»æ•°**: {len(self.results)}\n")
        
        # æ€»ä½“ç»Ÿè®¡
        passed = sum(1 for r in self.results if r.status == "é€šè¿‡")
        failed = sum(1 for r in self.results if r.status == "å¤±è´¥")
        error = sum(1 for r in self.results if r.status == "é”™è¯¯")
        pass_rate = (passed / len(self.results) * 100) if self.results else 0
        
        lines.append("\n## æµ‹è¯•æ‘˜è¦\n")
        lines.append(f"- âœ… **é€šè¿‡**: {passed}")
        lines.append(f"- âŒ **å¤±è´¥**: {failed}")
        lines.append(f"- âš ï¸ **é”™è¯¯**: {error}")
        lines.append(f"- ğŸ“Š **é€šè¿‡ç‡**: {pass_rate:.2f}%\n")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        lines.append("\n## æŒ‰ç±»åˆ«ç»Ÿè®¡\n")
        for category in ["product_lookup", "basic_query", "comparison_query", "rate_table_query", "exclusion_query"]:
            cat_results = [r for r in self.results if r.category == category]
            if not cat_results:
                continue
            
            cat_passed = sum(1 for r in cat_results if r.status == "é€šè¿‡")
            cat_failed = sum(1 for r in cat_results if r.status == "å¤±è´¥")
            cat_total = len(cat_results)
            cat_pass_rate = (cat_passed / cat_total * 100) if cat_total > 0 else 0
            
            lines.append(f"\n### {category.upper()}\n")
            lines.append(f"- æ€»æ•°: {cat_total}")
            lines.append(f"- é€šè¿‡: {cat_passed}")
            lines.append(f"- å¤±è´¥: {cat_failed}")
            lines.append(f"- é€šè¿‡ç‡: {cat_pass_rate:.2f}%\n")
        
        # è¯¦ç»†ç»“æœï¼ˆä»…æ˜¾ç¤ºå¤±è´¥å’Œé”™è¯¯çš„ï¼‰
        lines.append("\n## å¤±è´¥å’Œé”™è¯¯æ¡ˆä¾‹\n")
        failed_cases = [r for r in self.results if r.status in ["å¤±è´¥", "é”™è¯¯"]]
        
        if not failed_cases:
            lines.append("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!\n")
        else:
            for result in failed_cases:
                status_icon = "âŒ" if result.status == "å¤±è´¥" else "âš ï¸"
                lines.append(f"\n### {status_icon} {result.test_id}\n")
                lines.append(f"**ç±»åˆ«**: {result.category}\n")
                lines.append(f"**é—®é¢˜**: {result.question}\n")
                lines.append(f"**äº§å“**: {result.product_name or 'N/A'}\n")
                lines.append(f"**çŠ¶æ€**: {result.status}\n")
                if result.error:
                    lines.append(f"**é”™è¯¯**: {result.error}\n")
                if result.doc_type_correct is not None:
                    lines.append(f"**doc_typeæ­£ç¡®**: {result.doc_type_correct}\n")
        
        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        logger.info(f"MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    # æµ‹è¯•é›†è·¯å¾„
    test_set_path = project_root / "tests/golden_dataset/phase5_test_set_product_level.json"
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = ProductLevelTestRunner(str(test_set_path))
    
    # è¿è¡Œæµ‹è¯•
    runner.run_all_tests()
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_report_path = project_root / f"test_report_product_level_{timestamp}.json"
    md_report_path = project_root / f"test_report_product_level_{timestamp}.md"
    
    runner.generate_detailed_report(str(json_report_path))
    runner.generate_markdown_report(str(md_report_path))
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š(JSON): {json_report_path}")
    print(f"ğŸ“„ å¯è¯»æŠ¥å‘Š(Markdown): {md_report_path}")
