"""ç”Ÿæˆè¯¦ç»†çš„é—®ç­”æŠ¥å‘Š

ä»æµ‹è¯•runnerçš„ç»“æœç”ŸæˆåŒ…å«æ¯ä¸ªé—®é¢˜å’Œå®Œæ•´ç­”æ¡ˆçš„è¯¦ç»†æŠ¥å‘Šã€‚
"""
import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tests.test_runner_product_level import ProductLevelTestRunner

def generate_detailed_qa_report(runner: ProductLevelTestRunner, output_path: str):
    """ç”ŸæˆåŒ…å«å®Œæ•´é—®ç­”å¯¹çš„è¯¦ç»†æŠ¥å‘Š"""
    lines = ["# äº§å“çº§åˆ«æµ‹è¯• - è¯¦ç»†é—®ç­”æŠ¥å‘Š\n"]
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append(f"**æµ‹è¯•æ€»æ•°**: {len(runner.results)}\n")
    
    # æŒ‰ç±»åˆ«ç»„ç»‡
    categories = {
        "product_lookup": "äº§å“æŸ¥è¯¢æµ‹è¯•",
        "basic_query": "åŸºç¡€æŸ¥è¯¢æµ‹è¯•",
        "comparison_query": "å¯¹æ¯”æŸ¥è¯¢æµ‹è¯•",
        "rate_table_query": "è´¹ç‡è¡¨æŸ¥è¯¢æµ‹è¯•",
        "exclusion_query": "å…è´£æ¡æ¬¾æŸ¥è¯¢æµ‹è¯•"
    }
    
    for cat_key, cat_name in categories.items():
        cat_results = [r for r in runner.results if r.category == cat_key]
        if not cat_results:
            continue
        
        lines.append(f"\n---\n\n## {cat_name}\n")
        
        for i, result in enumerate(cat_results, 1):
            status_icon = "âœ…" if result.status == "é€šè¿‡" else "âŒ" if result.status == "å¤±è´¥" else "âš ï¸"
            
            lines.append(f"\n### {i}. {status_icon} {result.test_id}\n")
            lines.append(f"**é—®é¢˜**: {result.question}\n")
            
            if result.product_name:
                lines.append(f"**äº§å“**: {result.product_name}\n")
            if result.company:
                lines.append(f"**å…¬å¸**: {result.company}\n")
            
            lines.append(f"**çŠ¶æ€**: {result.status}\n")
            
            if result.error:
                lines.append(f"**é”™è¯¯**: {result.error}\n")
                lines.append("\n---\n")
                continue
            
            # æ˜¾ç¤ºMCPå“åº”
            if result.response:
                lines.append(f"\n**MCPè¿”å›** ({len(result.response)}æ¡ç»“æœ):\n")
                
                for j, resp in enumerate(result.response[:5], 1):  # æœ€å¤šæ˜¾ç¤ºTop-5
                    content_preview = ""  # åˆå§‹åŒ–
                    
                    # åˆ¤æ–­å“åº”ç±»å‹: ProductInfo æˆ– ClauseResult
                    if hasattr(resp, 'product_name') and hasattr(resp, 'product_code'):
                        # ProductInfo (æ¥è‡ªlookup_product)
                        lines.append(f"\n{j}. **{resp.product_name}**\n")
                        lines.append(f"   *äº§å“ä»£ç : {resp.product_code} | å…¬å¸: {resp.company}*\n")
                        if hasattr(resp, 'category'):
                            lines.append(f"   *ç±»åˆ«: {resp.category}*\n")
                        content_preview = f"äº§å“ç±»å‹: {getattr(resp, 'category', 'N/A')}"
                    else:
                        # ClauseResult (æ¥è‡ªsearch_policy_clause)
                        section_title = getattr(resp, 'section_title', 'æœªçŸ¥æ ‡é¢˜')
                        lines.append(f"\n{j}. **{section_title}**\n")
                        
                        # å…ƒæ•°æ®
                        metadata_parts = []
                        if hasattr(resp, 'similarity_score'):
                            metadata_parts.append(f"ç›¸ä¼¼åº¦: {resp.similarity_score:.4f}")
                        if hasattr(resp, 'doc_type'):
                            metadata_parts.append(f"ç±»å‹: {resp.doc_type}")
                        if hasattr(resp, 'source_reference') and resp.source_reference:
                            metadata_parts.append(f"äº§å“: {resp.source_reference.product_name}")
                        
                        if metadata_parts:
                            lines.append(f"   *{' | '.join(metadata_parts)}*\n")
                        
                        # å†…å®¹é¢„è§ˆ
                        content = getattr(resp, 'content', str(resp))
                        # æ¸…ç†æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼
                        content_clean = ' '.join(content.split())
                        content_preview = content_clean[:300] + "..." if len(content_clean) > 300 else content_clean
                    
                    if content_preview:
                        lines.append(f"\n   > {content_preview}\n")
            else:
                lines.append("\n**MCPè¿”å›**: æ— ç»“æœ\n")
            
            lines.append("\n---\n")
    
    # ä¿å­˜
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    print(f"âœ… è¯¦ç»†é—®ç­”æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    # åŠ è½½æµ‹è¯•é›†
    test_set_path = project_root / "tests/golden_dataset/phase5_test_set_product_level.json"
    
    print("æ­£åœ¨é‡æ–°è¿è¡Œæµ‹è¯•ä»¥è·å–å®Œæ•´å“åº”...")
    runner = ProductLevelTestRunner(str(test_set_path))
    runner.run_all_tests()
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    qa_report_path = project_root / f"test_qa_report_{timestamp}.md"
    
    generate_detailed_qa_report(runner, str(qa_report_path))
    
    print(f"\nğŸ“„ è¯¦ç»†é—®ç­”æŠ¥å‘Š: {qa_report_path}")
