"""ç«¯åˆ°ç«¯æµ‹è¯•è¿è¡Œå™¨ - 50é—®é¢˜é»„é‡‘æµ‹è¯•é›†

æ‰§è¡Œå®Œæ•´çš„50ä¸ªæµ‹è¯•ç”¨ä¾‹,ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šã€‚
"""
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.mcp_server.tools.search_policy_clause import SearchPolicyClauseTool
from src.common.logging import setup_logging

setup_logging()
logger = logging.getLogger(__name__)

class TestCaseResult:
    """æµ‹è¯•ç”¨ä¾‹ç»“æœ"""
    def __init__(self, test_case: Dict[str, Any]):
        self.test_id = test_case['id']
        self.question = test_case['question']
        self.query_type = test_case['query_type']
        self.expected_section_ids = test_case.get('expected_section_ids', [])
        self.expected_category = test_case.get('expected_category')
        self.min_similarity = test_case.get('min_similarity_score', 0.5)
        self.top_k = test_case.get('top_k', 5)
        
        # ç»“æœå­—æ®µ
        self.status = "æœªæ‰§è¡Œ"
        self.mcp_response = []  # List[ClauseResult]
        self.top_1_similarity = 0.0
        self.section_ids_matched = []
        self.category_distribution = {}
        self.error = None
        self.execution_time = 0.0
        
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "test_id": self.test_id,
            "question": self.question,
            "query_type": self.query_type,
            "expected_section_ids": self.expected_section_ids,
            "status": self.status,
            "top_1_similarity": self.top_1_similarity,
            "section_ids_matched": self.section_ids_matched,
            "category_distribution": self.category_distribution,
            "mcp_response_count": len(self.mcp_response),
            "execution_time_ms": round(self.execution_time * 1000, 2),
            "error": self.error
        }

class EndToEndTestRunner:
    """ç«¯åˆ°ç«¯æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, test_set_path: str):
        self.test_set_path = Path(test_set_path)
        self.test_data = self._load_test_set()
        self.results: List[TestCaseResult] = []
        self.search_tool = SearchPolicyClauseTool()
        
    def _load_test_set(self) -> Dict[str, Any]:
        """åŠ è½½æµ‹è¯•é›†"""
        with open(self.test_set_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
        logger.info(f"å¼€å§‹æ‰§è¡Œ{len(self.test_data['test_cases'])}ä¸ªæµ‹è¯•ç”¨ä¾‹...")
        
        for i, test_case in enumerate(self.test_data['test_cases'], 1):
            logger.info(f"[{i}/{len(self.test_data['test_cases'])}] æ‰§è¡Œ: {test_case['id']} - {test_case['question']}")
            result = self._run_single_test(test_case)
            self.results.append(result)
            
        logger.info("æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œå®Œæˆ")
    
    def _run_single_test(self, test_case: Dict[str, Any]) -> TestCaseResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        result = TestCaseResult(test_case)
        
        try:
            import time
            start_time = time.time()
            
            # è°ƒç”¨MCPå·¥å…·
            # å¦‚æœæµ‹è¯•ç”¨ä¾‹æœªæŒ‡å®šäº§å“ï¼Œé»˜è®¤ä½¿ç”¨"å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©ï¼ˆåˆ†çº¢å‹ï¼‰"
            product_name = test_case.get('product_name') or "å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©ï¼ˆåˆ†çº¢å‹ï¼‰"
            
            mcp_response = self.search_tool.run(
                query=test_case['question'],
                company=test_case.get('company', 'å¹³å®‰äººå¯¿'),
                product_name=product_name,
                n_results=result.top_k,
                min_similarity=result.min_similarity,
                auto_fetch_rate_tables=True
            )
            
            result.execution_time = time.time() - start_time
            result.mcp_response = mcp_response
            
            # åˆ†æç»“æœ
            if mcp_response:
                result.top_1_similarity = mcp_response[0].similarity_score
                
                # æå–åŒ¹é…çš„section_ids
                result.section_ids_matched = [
                    r.section_id for r in mcp_response if r.section_id
                ]
                
                # ç»Ÿè®¡categoryåˆ†å¸ƒ
                category_counts = {}
                for r in mcp_response:
                    cat = getattr(r, 'category', 'Unknown')
                    category_counts[cat] = category_counts.get(cat, 0) + 1
                result.category_distribution = category_counts
                
                # åˆ¤æ–­æˆåŠŸ/å¤±è´¥
                if result.expected_section_ids:
                    # æ£€æŸ¥æœŸæœ›çš„section_idæ˜¯å¦åœ¨ç»“æœä¸­
                    matched = any(
                        exp_id in result.section_ids_matched 
                        for exp_id in result.expected_section_ids
                    )
                    result.status = "é€šè¿‡" if matched else "å¤±è´¥"
                else:
                    # æ— Ground Truthæ—¶,æ ¹æ®ç›¸ä¼¼åº¦åˆ¤æ–­
                    result.status = "é€šè¿‡" if result.top_1_similarity >= result.min_similarity else "å¤±è´¥"
            else:
                result.status = "å¤±è´¥"
                result.error = "æœªè¿”å›ç»“æœ"
                
        except Exception as e:
            result.status = "é”™è¯¯"
            result.error = str(e)
            logger.error(f"æµ‹è¯•ç”¨ä¾‹ {test_case['id']} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        
        return result
    
    def generate_detailed_report(self, output_path: str):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š(JSON)"""
        report = {
            "test_set_name": self.test_data['name'],
            "test_set_version": self.test_data['version'],
            "total_count": len(self.results),
            "execution_time": datetime.now().isoformat(),
            "summary": self._generate_summary(),
            "detailed_results": []
        }
        
        for result in self.results:
            detailed = result.to_dict()
            # æ·»åŠ MCPå“åº”è¯¦æƒ…
            detailed['mcp_responses'] = [
                {
                    "rank": i + 1,
                    "chunk_id": r.chunk_id,
                    "content_preview": r.content[:200] + "..." if len(r.content) > 200 else r.content,
                    "section_id": r.section_id,
                    "section_title": r.section_title,
                    "similarity_score": round(r.similarity_score, 4),
                    "category": getattr(r, 'category', 'Unknown'),
                    "doc_type": r.doc_type if hasattr(r, 'doc_type') else 'äº§å“æ¡æ¬¾',
                    "product_name": r.source_reference.product_name,
                    "rate_table_content": r.rate_table_content  # æ·»åŠ è¡¨æ ¼å†…å®¹
                }
                for i, r in enumerate(result.mcp_response)
            ]
            report['detailed_results'].append(detailed)
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return report
    
    def generate_markdown_report(self, output_path: str):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        lines = ["# ç«¯åˆ°ç«¯æµ‹è¯•æŠ¥å‘Š - 50é—®é¢˜é»„é‡‘æµ‹è¯•é›†\n"]
        lines.append(f"**æµ‹è¯•é›†**: {self.test_data['name']}\n")
        lines.append(f"**æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        lines.append(f"**æµ‹è¯•ç”¨ä¾‹æ€»æ•°**: {len(self.results)}\n")
        
        # æ±‡æ€»ç»Ÿè®¡
        summary = self._generate_summary()
        lines.append("\n## æµ‹è¯•æ‘˜è¦\n")
        lines.append(f"- âœ… **é€šè¿‡**: {summary['passed']}")
        lines.append(f"- âŒ **å¤±è´¥**: {summary['failed']}")
        lines.append(f"- âš ï¸ **é”™è¯¯**: {summary['error']}")
        lines.append(f"- ğŸ“Š **é€šè¿‡ç‡**: {summary['pass_rate']:.2f}%\n")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        lines.append("\n## æŒ‰æŸ¥è¯¢ç±»å‹ç»Ÿè®¡\n")
        for qtype, stats in summary['by_type'].items():
            lines.append(f"\n### {qtype.upper()}\n")
            lines.append(f"- æ€»æ•°: {stats['total']}")
            lines.append(f"- é€šè¿‡: {stats['passed']}")
            lines.append(f"- å¤±è´¥: {stats['failed']}")
            lines.append(f"- é€šè¿‡ç‡: {stats['pass_rate']:.2f}%\n")
        
        # è¯¦ç»†ç»“æœ
        lines.append("\n## è¯¦ç»†æµ‹è¯•ç»“æœ\n")
        
        for i, result in enumerate(self.results, 1):
            status_icon = "âœ…" if result.status == "é€šè¿‡" else "âŒ" if result.status == "å¤±è´¥" else "âš ï¸"
            lines.append(f"\n### {i}. {status_icon} {result.test_id}\n")
            lines.append(f"**é—®é¢˜**: {result.question}\n")
            lines.append(f"**ç±»å‹**: {result.query_type} | **çŠ¶æ€**: {result.status}\n")
            
            if result.error:
                lines.append(f"**é”™è¯¯**: {result.error}\n")
                continue
            
            if result.mcp_response:
                lines.append(f"\n**Top-1ç›¸ä¼¼åº¦**: {result.top_1_similarity:.4f}\n")
                lines.append(f"**æœŸæœ›ç« èŠ‚**: {', '.join(result.expected_section_ids) if result.expected_section_ids else 'N/A'}\n")
                lines.append(f"**åŒ¹é…ç« èŠ‚**: {', '.join(result.section_ids_matched[:3])}\n")
                
                lines.append("\n**MCPè¿”å›ç»“æœ**:\n")
                for j, r in enumerate(result.mcp_response, 1):
                    lines.append(f"\n{j}. **{r.section_title}** (ç« èŠ‚: {r.section_id}, ç›¸ä¼¼åº¦: {r.similarity_score:.4f})")
                    
                    # å±•ç¤ºå†…å®¹é¢„è§ˆ
                    content_preview = r.content[:300].replace('\n', ' ') + "..."
                    lines.append(f"   > {content_preview}\n")
                    
                    # å¦‚æœæœ‰è¡¨æ ¼å†…å®¹ï¼Œå±•ç¤ºå‡ºæ¥
                    if r.rate_table_content:
                        lines.append("\n   **ğŸ“Š é™„å¸¦è¡¨æ ¼æ•°æ®**:\n")
                        # ç¼©è¿›è¡¨æ ¼å†…å®¹ä»¥ä¾¿é˜…è¯»
                        table_lines = r.rate_table_content.split('\n')
                        for tl in table_lines:
                            lines.append(f"   {tl}")
                        lines.append("\n")
            
            lines.append("\n" + "-" * 80 + "\n")
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        logger.info(f"MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦ç»Ÿè®¡"""
        passed = sum(1 for r in self.results if r.status == "é€šè¿‡")
        failed = sum(1 for r in self.results if r.status == "å¤±è´¥")
        error = sum(1 for r in self.results if r.status == "é”™è¯¯")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        by_type = {}
        for result in self.results:
            qtype = result.query_type
            if qtype not in by_type:
                by_type[qtype] = {"total": 0, "passed": 0, "failed": 0, "error": 0}
            by_type[qtype]["total"] += 1
            if result.status == "é€šè¿‡":
                by_type[qtype]["passed"] += 1
            elif result.status == "å¤±è´¥":
                by_type[qtype]["failed"] += 1
            else:
                by_type[qtype]["error"] += 1
        
        # è®¡ç®—é€šè¿‡ç‡
        for stats in by_type.values():
            stats['pass_rate'] = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0
        
        return {
            "total": len(self.results),
            "passed": passed,
            "failed": failed,
            "error": error,
            "pass_rate": (passed / len(self.results) * 100) if self.results else 0,
            "by_type": by_type
        }

if __name__ == "__main__":
    # æµ‹è¯•é›†è·¯å¾„
    test_set_path = project_root / "tests/golden_dataset/phase5_test_set_labeled.json"
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = EndToEndTestRunner(str(test_set_path))
    
    # è¿è¡Œæµ‹è¯•
    runner.run_all_tests()
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_report_path = project_root / f"test_report_{timestamp}.json"
    md_report_path = project_root / f"test_report_{timestamp}.md"
    
    runner.generate_detailed_report(str(json_report_path))
    runner.generate_markdown_report(str(md_report_path))
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š(JSON): {json_report_path}")
    print(f"ğŸ“„ å¯è¯»æŠ¥å‘Š(Markdown): {md_report_path}")
