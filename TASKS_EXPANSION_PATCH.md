# tasks.md æ‰©å±•è¡¥ä¸

## ğŸ¯ ä½¿ç”¨è¯´æ˜

æœ¬æ–‡ä»¶åŒ…å«éœ€è¦æ·»åŠ åˆ° `specs/001-insurance-mcp-core/tasks.md` ä¸­çš„æ–°ä»»åŠ¡ã€‚
è¿™äº›ä»»åŠ¡ç”¨äºå¡«è¡¥ç¬¬äº”é˜¶æ®µï¼ˆå‘é‡åŒ–ç´¢å¼•ï¼‰çš„å®æ–½gapã€‚

---

## æ–°å¢ä»»åŠ¡ï¼šç¬¬äº”é˜¶æ®µæ‰©å±•

**ä½ç½®**: åœ¨ `## ç¬¬äº”é˜¶æ®µï¼šAI å®¢æˆ·ç«¯æ£€ç´¢ (ç”¨æˆ·æ•…äº‹ 1)` ç« èŠ‚ä¸­æ’å…¥ä»¥ä¸‹ä»»åŠ¡

---

### T020a [US1] Markdownåå¤„ç†Pipeline

**ä¼˜å…ˆçº§**: P0 (æœ€é«˜ä¼˜å…ˆçº§ - å¿…é¡»åœ¨ç´¢å¼•å‰å®Œæˆ)

**ç›®æ ‡**: å®ç°Markdownæ–‡æ¡£çš„åå¤„ç†æ¸…æ´—ï¼Œä¼˜åŒ–å‘é‡æ£€ç´¢æ•ˆæœã€‚

**æ–‡ä»¶**: `src/parser/markdown/postprocessor.py`

**åŠŸèƒ½éœ€æ±‚**:

1. **è„šæ³¨å†…è”å¤„ç†**:
   ```python
   class FootnoteInliner:
       """
       å°†æ–‡æ¡£æœ«å°¾çš„è„šæ³¨ï¼ˆåè¯è§£é‡Šï¼‰å†…è”åˆ°æ­£æ–‡ä¸­
       
       ç¤ºä¾‹:
       åŸæ–‡: "è¢«ä¿é™©äººâ½Â¹â¾åº”åœ¨..."
       è„šæ³¨: "â½Â¹â¾è¢«ä¿é™©äººæŒ‡å—ä¿é™©åˆåŒä¿éšœçš„äºº"
       å¤„ç†å: "è¢«ä¿é™©äººï¼ˆæŒ‡å—ä¿é™©åˆåŒä¿éšœçš„äººï¼‰åº”åœ¨..."
       """
       def inline_footnotes(self, markdown_text: str) -> str:
           # 1. æå–æ‰€æœ‰è„šæ³¨ï¼ˆæ­£åˆ™åŒ¹é… â½æ•°å­—â¾ æˆ– [æ•°å­—]ï¼‰
           # 2. åœ¨æ­£æ–‡ä¸­æ‰¾åˆ°è„šæ³¨å¼•ç”¨
           # 3. å°†å®šä¹‰æ’å…¥åˆ°å¼•ç”¨å
           # 4. åˆ é™¤æ–‡æ¡£æœ«å°¾çš„è„šæ³¨éƒ¨åˆ†
           pass
   ```

2. **å™ªéŸ³å»é™¤**:
   ```python
   class NoiseRemover:
       """ç§»é™¤é¡µçœ‰ã€é¡µè„šã€æ°´å°ç­‰æ— ç”¨å†…å®¹"""
       
       NOISE_PATTERNS = [
           r"å¹³å®‰äººå¯¿\s*ç¬¬\s*\d+\s*é¡µ",  # é¡µç 
           r"è¯·æ‰«æä»¥æŸ¥è¯¢éªŒè¯æ¡æ¬¾",        # æ°´å°
           r"={10,}",                      # åˆ†éš”ç¬¦
           r"ä¿å¯†ä¿¡æ¯ï¼Œä»…ä¾›å†…éƒ¨ä½¿ç”¨"        # ä¿å¯†æ ‡è¯†
       ]
       
       def remove_noise(self, markdown_text: str) -> str:
           # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤å™ªéŸ³æ¨¡å¼
           pass
   ```

3. **æ ¼å¼æ ‡å‡†åŒ–**:
   ```python
   class FormatStandardizer:
       """æ ‡å‡†åŒ–Markdownæ ¼å¼"""
       
       def standardize(self, markdown_text: str) -> str:
           # 1. ç»Ÿä¸€æ ‡é¢˜å±‚çº§ï¼ˆ# -> äº§å“åï¼Œ## -> ç« èŠ‚ï¼Œ### -> æ¡æ¬¾ï¼‰
           # 2. ç»Ÿä¸€åˆ—è¡¨æ ¼å¼ï¼ˆæ··ç”¨ - å’Œ 1. æ—¶ç»Ÿä¸€ä¸º -ï¼‰
           # 3. ä¿®æ­£ç¹ç®€æ··ç”¨ï¼ˆ"ä¿éšªäºº" -> "ä¿é™©äºº"ï¼‰
           # 4. è§„èŒƒåŒ–ç©ºç™½è¡Œï¼ˆç« èŠ‚é—´ä¿ç•™ä¸€ä¸ªç©ºè¡Œï¼‰
           pass
   ```

4. **è¡¨æ ¼éªŒè¯**:
   ```python
   class TableValidator:
       """éªŒè¯å’Œæ ‡è®°è¡¨æ ¼chunk"""
       
       def validate_tables(self, markdown_text: str) -> Tuple[str, List[TableMetadata]]:
           # 1. æ£€æµ‹Markdownè¡¨æ ¼ï¼ˆ| åˆ— | æ ¼å¼ï¼‰
           # 2. éªŒè¯è¡Œåˆ—å®Œæ•´æ€§ï¼ˆheaderè¡Œã€åˆ†éš”è¡Œã€æ•°æ®è¡Œï¼‰
           # 3. ä¸ºå¤æ‚è¡¨æ ¼ç”ŸæˆJSONç»“æ„
           # 4. è¿”å›å¤„ç†åçš„æ–‡æœ¬ + è¡¨æ ¼å…ƒæ•°æ®åˆ—è¡¨
           pass
   ```

**Pipelineé›†æˆ**:
```python
class MarkdownPostProcessor:
    def __init__(self):
        self.footnote_inliner = FootnoteInliner()
        self.noise_remover = NoiseRemover()
        self.format_standardizer = FormatStandardizer()
        self.table_validator = TableValidator()
    
    def process(self, markdown_path: Path) -> ProcessedMarkdown:
        """æ‰§è¡Œå®Œæ•´çš„åå¤„ç†æµç¨‹"""
        text = markdown_path.read_text(encoding='utf-8')
        
        # æ‰§è¡Œæ¸…æ´—æ­¥éª¤
        text = self.footnote_inliner.inline_footnotes(text)
        text = self.noise_remover.remove_noise(text)
        text = self.format_standardizer.standardize(text)
        text, table_metadata = self.table_validator.validate_tables(text)
        
        return ProcessedMarkdown(
            content=text,
            tables=table_metadata,
            processed_at=datetime.now()
        )
```

**CLIå‘½ä»¤**:
```bash
# åå¤„ç†å•ä¸ªæ–‡æ¡£
python -m src.cli.manage process postprocess --doc-id 067afcfc

# æ‰¹é‡åå¤„ç†æ‰€æœ‰VERIFIEDæ–‡æ¡£
python -m src.cli.manage process postprocess --all
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] è„šæ³¨å†…è”æˆåŠŸç‡ > 95%ï¼ˆæ‰‹åŠ¨æŠ½æ£€10ä»½æ–‡æ¡£ï¼‰
- [ ] å™ªéŸ³å»é™¤ä¸å½±å“æ­£æ–‡å†…å®¹ï¼ˆé›¶è¯¯æ€ï¼‰
- [ ] è¡¨æ ¼å®Œæ•´æ€§éªŒè¯é€šè¿‡ç‡ 100%
- [ ] å¤„ç†åçš„æ–‡æ¡£ä»ç¬¦åˆMarkdownè§„èŒƒ

**ä¾èµ–**:
- ä¾èµ– T019ï¼ˆå®¡æ ¸å‘˜CLIï¼‰ï¼Œåªå¤„ç†VERIFIEDçŠ¶æ€çš„æ–‡æ¡£
- ä¸º T023ï¼ˆç´¢å¼•å™¨ï¼‰æä¾›æ¸…æ´—åçš„è¾“å…¥

**æµ‹è¯•ç”¨ä¾‹**:
```python
def test_footnote_inliner():
    input_text = "è¢«ä¿é™©äººâ½Â¹â¾åº”åœ¨...\n\nâ½Â¹â¾è¢«ä¿é™©äººæŒ‡å—ä¿é™©åˆåŒä¿éšœçš„äºº"
    expected = "è¢«ä¿é™©äººï¼ˆæŒ‡å—ä¿é™©åˆåŒä¿éšœçš„äººï¼‰åº”åœ¨..."
    assert FootnoteInliner().inline_footnotes(input_text) == expected

def test_table_validator():
    input_table = """
    | ä¿å•å¹´åº¦ | é‡‘é¢ |
    |---------|------|
    | ç¬¬5å¹´   | 1000 |
    """
    text, metadata = TableValidator().validate_tables(input_table)
    assert len(metadata) == 1
    assert metadata[0].is_valid == True
    assert metadata[0].rows == 1
    assert metadata[0].columns == 2
```

---

### T022a [US1] æ··åˆæ£€ç´¢å®ç°

**ä¼˜å…ˆçº§**: P0 (CRITICAL - å“åº”Constitution 4.1è¦æ±‚)

**ç›®æ ‡**: å®ç°è¯­ä¹‰æ£€ç´¢ï¼ˆDense Vectorï¼‰ä¸å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰çš„æ··åˆæ¨¡å¼ã€‚

**æ–‡ä»¶**: 
- `src/indexing/vector_store/hybrid_retriever.py`
- `src/indexing/vector_store/bm25_index.py`

**æ¶æ„è®¾è®¡**:

```python
# bm25_index.py
from rank_bm25 import BM25Okapi
import pickle

class BM25Index:
    """
    BM25å…³é”®è¯æ£€ç´¢ç´¢å¼•
    
    ç”¨äºç²¾ç¡®åŒ¹é…ä¸“æœ‰åè¯ï¼ˆå¦‚"189å·"ã€"å‡é¢äº¤æ¸…"ã€"çŠ¹è±«æœŸ"ï¼‰
    """
    
    def __init__(self, index_path: Path):
        self.index_path = index_path
        self.corpus = []  # æ–‡æ¡£åˆ—è¡¨
        self.doc_ids = []  # æ–‡æ¡£IDåˆ—è¡¨
        self.bm25 = None
        
    def build(self, documents: List[Document]):
        """æ„å»ºBM25ç´¢å¼•"""
        self.corpus = [doc.content for doc in documents]
        self.doc_ids = [doc.id for doc in documents]
        
        # åˆ†è¯ï¼ˆç®€å•ç‰ˆæœ¬ï¼šæŒ‰ç©ºæ ¼+æ ‡ç‚¹åˆ†è¯ï¼‰
        tokenized_corpus = [self._tokenize(doc) for doc in self.corpus]
        
        # æ„å»ºBM25ç´¢å¼•
        self.bm25 = BM25Okapi(tokenized_corpus)
        
        # æŒä¹…åŒ–
        self._save()
    
    def _tokenize(self, text: str) -> List[str]:
        """åˆ†è¯ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰"""
        import jieba
        return list(jieba.cut(text))
    
    def search(self, query: str, top_k: int = 10) -> List[SearchResult]:
        """BM25æ£€ç´¢"""
        tokenized_query = self._tokenize(query)
        scores = self.bm25.get_scores(tokenized_query)
        
        # è·å–top-kç»“æœ
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            if scores[idx] > 0:  # è¿‡æ»¤é›¶åˆ†ç»“æœ
                results.append(SearchResult(
                    doc_id=self.doc_ids[idx],
                    content=self.corpus[idx],
                    score=scores[idx],
                    method="BM25"
                ))
        
        return results
    
    def _save(self):
        """ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜"""
        with open(self.index_path, 'wb') as f:
            pickle.dump({
                'corpus': self.corpus,
                'doc_ids': self.doc_ids,
                'bm25': self.bm25
            }, f)
    
    @classmethod
    def load(cls, index_path: Path):
        """ä»ç£ç›˜åŠ è½½ç´¢å¼•"""
        instance = cls(index_path)
        with open(index_path, 'rb') as f:
            data = pickle.load(f)
            instance.corpus = data['corpus']
            instance.doc_ids = data['doc_ids']
            instance.bm25 = data['bm25']
        return instance


# hybrid_retriever.py
class HybridRetriever:
    """
    æ··åˆæ£€ç´¢å™¨
    
    ç»“åˆChromaDBï¼ˆè¯­ä¹‰ï¼‰å’ŒBM25ï¼ˆå…³é”®è¯ï¼‰çš„æ£€ç´¢ç»“æœ
    """
    
    def __init__(self, chroma_client, bm25_index: BM25Index):
        self.chroma = chroma_client
        self.bm25 = bm25_index
        
    def search(
        self, 
        query: str, 
        top_k: int = 10,
        semantic_weight: float = 0.6,
        bm25_weight: float = 0.4,
        filters: Optional[Dict] = None
    ) -> List[SearchResult]:
        """
        æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°
            semantic_weight: è¯­ä¹‰æ£€ç´¢æƒé‡ï¼ˆé»˜è®¤0.6ï¼‰
            bm25_weight: BM25æƒé‡ï¼ˆé»˜è®¤0.4ï¼‰
            filters: metadataè¿‡æ»¤æ¡ä»¶ï¼ˆå¦‚ {"category": "Exclusion"}ï¼‰
        """
        
        # è‡ªåŠ¨è°ƒæ•´æƒé‡ï¼ˆå¯å‘å¼è§„åˆ™ï¼‰
        if self._contains_numbers(query):
            # æŸ¥è¯¢åŒ…å«æ•°å­—ï¼ˆå¦‚"1.2.1æ¡æ¬¾"ï¼‰ï¼Œæå‡BM25æƒé‡
            semantic_weight, bm25_weight = 0.2, 0.8
        elif self._is_question(query):
            # æŸ¥è¯¢æ˜¯é—®å¥ï¼ˆå¦‚"å¦‚ä½•é€€ä¿ï¼Ÿ"ï¼‰ï¼Œæå‡è¯­ä¹‰æƒé‡
            semantic_weight, bm25_weight = 0.8, 0.2
        
        # 1. è¯­ä¹‰æ£€ç´¢
        semantic_results = self.chroma.query(
            query_texts=[query],
            n_results=top_k * 2,  # æ£€ç´¢2å€ç»“æœç”¨äºèåˆ
            where=filters
        )
        
        # 2. BM25æ£€ç´¢
        bm25_results = self.bm25.search(query, top_k=top_k * 2)
        
        # 3. Reciprocal Rank Fusion (RRF)
        fused_results = self._reciprocal_rank_fusion(
            semantic_results,
            bm25_results,
            semantic_weight,
            bm25_weight
        )
        
        return fused_results[:top_k]
    
    def _reciprocal_rank_fusion(
        self, 
        semantic_results: List, 
        bm25_results: List,
        w1: float,
        w2: float,
        k: int = 60
    ) -> List[SearchResult]:
        """
        RRFç®—æ³•èåˆä¸¤ä¸ªæ’åºåˆ—è¡¨
        
        å…¬å¼: score(d) = w1 * 1/(k + rank1(d)) + w2 * 1/(k + rank2(d))
        """
        scores = defaultdict(float)
        
        # è¯­ä¹‰æ£€ç´¢ç»“æœ
        for rank, result in enumerate(semantic_results, start=1):
            doc_id = result['id']
            scores[doc_id] += w1 / (k + rank)
        
        # BM25ç»“æœ
        for rank, result in enumerate(bm25_results, start=1):
            doc_id = result.doc_id
            scores[doc_id] += w2 / (k + rank)
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_results = []
        for doc_id, score in sorted_docs:
            # è·å–æ–‡æ¡£å†…å®¹ï¼ˆä»ChromaDBæˆ–BM25ï¼‰
            doc = self._get_document(doc_id)
            final_results.append(SearchResult(
                doc_id=doc_id,
                content=doc.content,
                score=score,
                method="Hybrid (RRF)"
            ))
        
        return final_results
    
    def _contains_numbers(self, query: str) -> bool:
        """æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆå¦‚"1.2.1"ï¼‰"""
        return bool(re.search(r'\d+\.\d+', query))
    
    def _is_question(self, query: str) -> bool:
        """æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦ä¸ºé—®å¥"""
        question_words = ['å¦‚ä½•', 'æ€ä¹ˆ', 'ä»€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ª', 'å¤šå°‘', 'å—', 'å‘¢', '?', 'ï¼Ÿ']
        return any(word in query for word in question_words)
```

**CLIå‘½ä»¤**:
```bash
# æ„å»ºBM25ç´¢å¼•ï¼ˆåœ¨æ„å»ºChromaDBç´¢å¼•æ—¶åŒæ­¥æ‰§è¡Œï¼‰
python -m src.cli.manage index --rebuild

# æµ‹è¯•æ··åˆæ£€ç´¢
python -m src.cli.manage index test-search "1.2.1æ¡æ¬¾å†…å®¹" --method hybrid
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] ä¸“æœ‰åè¯æŸ¥è¯¢ï¼ˆå¦‚"189å·"ï¼‰BM25æƒé‡è‡ªåŠ¨æå‡è‡³80%
- [ ] é—®å¥æŸ¥è¯¢ï¼ˆå¦‚"å¦‚ä½•é€€ä¿ï¼Ÿ"ï¼‰è¯­ä¹‰æƒé‡è‡ªåŠ¨æå‡è‡³80%
- [ ] æ··åˆæ£€ç´¢æ¯”çº¯è¯­ä¹‰æ£€ç´¢å‡†ç¡®ç‡æå‡ > 15%ï¼ˆä½¿ç”¨é»„é‡‘æµ‹è¯•é›†éªŒè¯ï¼‰
- [ ] å“åº”æ—¶é—´ < 2ç§’

**ä¾èµ–**:
- ä¾èµ– T020aï¼ˆåå¤„ç†ï¼‰æä¾›æ¸…æ´—åçš„æ–‡æœ¬
- ä¾èµ– T022ï¼ˆChromaDBå®ç°ï¼‰
- æ–°å¢Pythonä¾èµ–ï¼š`rank-bm25`, `jieba`ï¼ˆä¸­æ–‡åˆ†è¯ï¼‰

**æµ‹è¯•ç”¨ä¾‹**:
```python
@pytest.mark.asyncio
async def test_hybrid_search_with_numbers():
    """æµ‹è¯•åŒ…å«æ•°å­—çš„æŸ¥è¯¢è‡ªåŠ¨æå‡BM25æƒé‡"""
    retriever = HybridRetriever(chroma_client, bm25_index)
    results = retriever.search("1.2.1æ¡æ¬¾")
    
    # éªŒè¯ç¬¬ä¸€ä¸ªç»“æœç¡®å®åŒ…å«"1.2.1"
    assert "1.2.1" in results[0].content

@pytest.mark.asyncio
async def test_hybrid_search_question():
    """æµ‹è¯•é—®å¥æŸ¥è¯¢è‡ªåŠ¨æå‡è¯­ä¹‰æƒé‡"""
    retriever = HybridRetriever(chroma_client, bm25_index)
    results = retriever.search("å¦‚ä½•ç”³è¯·é€€ä¿ï¼Ÿ")
    
    # éªŒè¯ç»“æœåŒ…å«é€€ä¿ç›¸å…³æ¡æ¬¾
    assert any("é€€ä¿" in r.content for r in results)
```

---

### T023a [US1] è¡¨æ ¼ç‹¬ç«‹Chunkå¤„ç†

**ä¼˜å…ˆçº§**: P0 (CRITICAL - å“åº”Constitution 3.2è¦æ±‚)

**ç›®æ ‡**: ç¡®ä¿è¡¨æ ¼ä½œä¸ºç‹¬ç«‹chunkå­˜å‚¨ï¼Œé˜²æ­¢è¡Œåˆ—å…³ç³»å´©åã€‚

**æ–‡ä»¶**: `src/indexing/chunker.py` (æ‰©å±•ç°æœ‰å®ç°)

**å®ç°é€»è¾‘**:

```python
class SemanticChunker:
    """
    è¯­ä¹‰æ„ŸçŸ¥çš„Chunkç”Ÿæˆå™¨
    
    åŸºäºMarkdownæ ‡é¢˜å±‚çº§åˆ‡åˆ†ï¼Œç‰¹æ®Šå¤„ç†è¡¨æ ¼
    """
    
    def __init__(
        self,
        target_size: int = 512,
        max_size: int = 1024,
        overlap: int = 100,
        enable_table_protection: bool = True
    ):
        self.target_size = target_size
        self.max_size = max_size
        self.overlap = overlap
        self.enable_table_protection = enable_table_protection
        
    def chunk_document(self, markdown_text: str, doc_id: str) -> List[PolicyChunk]:
        """
        åˆ‡åˆ†æ–‡æ¡£ä¸ºchunks
        
        æµç¨‹:
        1. è¯†åˆ«æ‰€æœ‰è¡¨æ ¼ä½ç½®
        2. æå–è¡¨æ ¼ä½œä¸ºç‹¬ç«‹chunks
        3. å¯¹éè¡¨æ ¼éƒ¨åˆ†æŒ‰æ ‡é¢˜å±‚çº§åˆ‡åˆ†
        4. åˆå¹¶ç»“æœ
        """
        chunks = []
        
        # 1. è¯†åˆ«å¹¶æå–è¡¨æ ¼
        table_chunks = []
        if self.enable_table_protection:
            markdown_text, table_chunks = self._extract_tables(markdown_text, doc_id)
        
        # 2. å¯¹å‰©ä½™æ–‡æœ¬æŒ‰æ ‡é¢˜å±‚çº§åˆ‡åˆ†
        text_chunks = self._split_by_headers(markdown_text, doc_id)
        
        # 3. åˆå¹¶å¹¶æ’åºï¼ˆæŒ‰åŸæ–‡é¡ºåºï¼‰
        all_chunks = sorted(
            table_chunks + text_chunks,
            key=lambda c: c.chunk_index
        )
        
        return all_chunks
    
    def _extract_tables(
        self, 
        markdown_text: str, 
        doc_id: str
    ) -> Tuple[str, List[PolicyChunk]]:
        """
        æå–è¡¨æ ¼å¹¶è½¬æ¢ä¸ºç‹¬ç«‹chunks
        
        Returns:
            (å»é™¤è¡¨æ ¼åçš„æ–‡æœ¬, è¡¨æ ¼chunksåˆ—è¡¨)
        """
        table_chunks = []
        table_pattern = r'\|[^\n]+\|\n\|[-:| ]+\|\n(\|[^\n]+\|\n)+'
        
        for match in re.finditer(table_pattern, markdown_text):
            table_md = match.group(0)
            start_pos = match.start()
            
            # æå–è¡¨æ ¼å‰çš„æ ‡é¢˜ä½œä¸ºä¸Šä¸‹æ–‡
            context = self._get_table_context(markdown_text, start_pos)
            
            # è§£æè¡¨æ ¼ä¸ºJSON
            table_data = self._parse_table_to_json(table_md)
            
            # åˆ›å»ºè¡¨æ ¼chunk
            chunk = PolicyChunk(
                id=f"{doc_id}_table_{len(table_chunks)}",
                document_id=doc_id,
                content=f"{context}\n\n{table_md}",  # åŒ…å«ä¸Šä¸‹æ–‡
                is_table=True,
                table_data=table_data,
                metadata={
                    "table_type": self._infer_table_type(context),
                    "rows": table_data["row_count"],
                    "columns": table_data["column_count"]
                },
                chunk_index=start_pos  # ç”¨äºæ’åº
            )
            table_chunks.append(chunk)
        
        # ä»åŸæ–‡æœ¬ä¸­ç§»é™¤è¡¨æ ¼ï¼ˆç”¨å ä½ç¬¦æ›¿æ¢ï¼Œä¿æŒä½ç½®ï¼‰
        cleaned_text = re.sub(table_pattern, "[TABLE_PLACEHOLDER]", markdown_text)
        
        return cleaned_text, table_chunks
    
    def _parse_table_to_json(self, table_md: str) -> Dict:
        """
        è§£æMarkdownè¡¨æ ¼ä¸ºJSONç»“æ„
        
        ç¤ºä¾‹:
        Input:
        | ä¿å•å¹´åº¦ | é‡‘é¢ |
        |---------|------|
        | ç¬¬5å¹´   | 1000 |
        
        Output:
        {
            "headers": ["ä¿å•å¹´åº¦", "é‡‘é¢"],
            "rows": [["ç¬¬5å¹´", "1000"]],
            "row_count": 1,
            "column_count": 2
        }
        """
        lines = table_md.strip().split('\n')
        headers = [cell.strip() for cell in lines[0].split('|')[1:-1]]
        
        rows = []
        for line in lines[2:]:  # è·³è¿‡åˆ†éš”è¡Œ
            cells = [cell.strip() for cell in line.split('|')[1:-1]]
            rows.append(cells)
        
        return {
            "headers": headers,
            "rows": rows,
            "row_count": len(rows),
            "column_count": len(headers)
        }
    
    def _get_table_context(self, text: str, table_start_pos: int, lines: int = 3) -> str:
        """è·å–è¡¨æ ¼å‰çš„å‡ è¡Œä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆé€šå¸¸æ˜¯è¡¨æ ¼æ ‡é¢˜ï¼‰"""
        before_text = text[:table_start_pos]
        context_lines = before_text.split('\n')[-lines:]
        return '\n'.join(context_lines)
    
    def _infer_table_type(self, context: str) -> str:
        """æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­è¡¨æ ¼ç±»å‹"""
        type_keywords = {
            "å‡é¢äº¤æ¸…": "å‡é¢äº¤æ¸…å¯¹æ¯”è¡¨",
            "ç°é‡‘ä»·å€¼": "ç°é‡‘ä»·å€¼è¡¨",
            "è´¹ç‡": "è´¹ç‡è¡¨",
            "åˆ©ç›Š": "åˆ©ç›Šæ¼”ç¤ºè¡¨"
        }
        for keyword, table_type in type_keywords.items():
            if keyword in context:
                return table_type
        return "æœªçŸ¥è¡¨æ ¼"
    
    def _split_by_headers(self, text: str, doc_id: str) -> List[PolicyChunk]:
        """
        æŒ‰Markdownæ ‡é¢˜å±‚çº§åˆ‡åˆ†æ–‡æœ¬
        
        ä½¿ç”¨LangChainçš„MarkdownHeaderTextSplitteræˆ–è‡ªå®ç°
        """
        from langchain.text_splitter import MarkdownHeaderTextSplitter
        
        headers_to_split_on = [
            ("#", "äº§å“åç§°"),
            ("##", "ç« èŠ‚"),
            ("###", "æ¡æ¬¾"),
        ]
        
        splitter = MarkdownHeaderTextSplitter(headers_to_split_on)
        splits = splitter.split_text(text)
        
        chunks = []
        for i, split in enumerate(splits):
            # æå–metadata
            section_id = self._extract_section_id(split.metadata)
            category = self._classify_category(split.page_content)
            
            chunk = PolicyChunk(
                id=f"{doc_id}_text_{i}",
                document_id=doc_id,
                content=split.page_content,
                is_table=False,
                metadata={
                    "section_id": section_id,
                    "section_title": split.metadata.get("æ¡æ¬¾", ""),
                    "category": category,
                    "level": len([h for h in headers_to_split_on if h[1] in split.metadata])
                },
                chunk_index=i * 1000  # ç®€å•æ’åºï¼Œè¡¨æ ¼ä¼šæ’å…¥åˆ°æ­£ç¡®ä½ç½®
            )
            chunks.append(chunk)
        
        return chunks
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] è¡¨æ ¼chunkçš„ `is_table=True` æ ‡è®°å‡†ç¡®ç‡ 100%
- [ ] è¡¨æ ¼JSONç»“æ„å®Œæ•´æ€§ï¼ˆè¡Œåˆ—å®Œæ•´ï¼‰100%
- [ ] å¤æ‚è¡¨æ ¼ï¼ˆå¦‚å‡é¢äº¤æ¸…è¡¨ï¼‰èƒ½æ­£ç¡®è§£æä¸ºJSON
- [ ] è¡¨æ ¼chunkåŒ…å«ä¸Šä¸‹æ–‡æ ‡é¢˜ï¼ˆä¾¿äºç†è§£è¡¨æ ¼å«ä¹‰ï¼‰

**ä¾èµ–**:
- ä¾èµ– T020aï¼ˆåå¤„ç†ï¼‰æä¾›æ ‡å‡†åŒ–çš„è¡¨æ ¼æ ¼å¼
- æ–°å¢Pythonä¾èµ–ï¼š`langchain`ï¼ˆMarkdownHeaderTextSplitterï¼‰

**æµ‹è¯•ç”¨ä¾‹**:
```python
def test_table_extraction():
    """æµ‹è¯•è¡¨æ ¼æå–å’ŒJSONè½¬æ¢"""
    markdown = """
    ### 6.4 å‡é¢äº¤æ¸…å¯¹æ¯”è¡¨
    
    | ä¿å•å¹´åº¦ | å‡é¢åå¹´é‡‘ | å¤‡æ³¨ |
    |---------|-----------|------|
    | ç¬¬5å¹´   | 1000å…ƒ/å¹´ | ç»ˆèº«é¢†å– |
    | ç¬¬10å¹´  | 1500å…ƒ/å¹´ | ç»ˆèº«é¢†å– |
    """
    
    chunker = SemanticChunker(enable_table_protection=True)
    chunks = chunker.chunk_document(markdown, "test_doc")
    
    # åº”è¯¥æœ‰ä¸€ä¸ªè¡¨æ ¼chunk
    table_chunks = [c for c in chunks if c.is_table]
    assert len(table_chunks) == 1
    
    # éªŒè¯JSONç»“æ„
    table_data = table_chunks[0].table_data
    assert table_data["row_count"] == 2
    assert table_data["column_count"] == 3
    assert "å‡é¢åå¹´é‡‘" in table_data["headers"]
```

---

### T025a [US1] é‡æ–°è®¾è®¡MCPå·¥å…·

**ä¼˜å…ˆçº§**: P0 (HIGH - æ ¸å¿ƒç”¨æˆ·ä½“éªŒ)

**ç›®æ ‡**: æ ¹æ®ä¼˜åŒ–å»ºè®®é‡æ–°è®¾è®¡MCPå·¥å…·ï¼Œæä¾›æ›´ç²¾å‡†çš„ä¿é™©æ¡æ¬¾æŸ¥è¯¢èƒ½åŠ›ã€‚

**æ–‡ä»¶**:
- `src/mcp_server/tools/search_clause.py` (æ–°å»º)
- `src/mcp_server/tools/check_exclusion.py` (æ–°å»º)
- `src/mcp_server/tools/surrender_logic.py` (æ–°å»º)
- `src/mcp_server/server.py` (æ›´æ–°å·¥å…·æ³¨å†Œ)

**å®ç°ç¤ºä¾‹ - Tool 1: search_policy_clause**

```python
# search_clause.py
from mcp.server.models import Tool
from pydantic import BaseModel
from typing import Optional, List

class SearchPolicyClauseInput(BaseModel):
    query: str
    company: Optional[str] = None
    product: Optional[str] = None
    category: Optional[str] = None
    top_k: int = 5

class ClauseResult(BaseModel):
    chunk_id: str
    content: str
    section_id: str
    section_title: str
    similarity_score: float
    source_reference: dict

async def search_policy_clause(input: SearchPolicyClauseInput) -> List[ClauseResult]:
    """
    è¯­ä¹‰æ¡æ¬¾æ£€ç´¢å·¥å…·
    
    ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰æŸ¥æ‰¾ä¿é™©æ¡æ¬¾
    """
    # æ„å»ºmetadataè¿‡æ»¤å™¨
    filters = {}
    if input.company:
        filters["company"] = input.company
    if input.product:
        filters["product_name"] = input.product
    if input.category:
        filters["category"] = input.category
    
    # ä½¿ç”¨æ··åˆæ£€ç´¢å™¨
    from src.indexing.vector_store.hybrid_retriever import get_hybrid_retriever
    retriever = get_hybrid_retriever()
    
    results = await retriever.search(
        query=input.query,
        top_k=input.top_k,
        filters=filters if filters else None
    )
    
    # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
    filtered_results = [r for r in results if r.similarity_score > 0.7]
    
    # è½¬æ¢ä¸ºClauseResult
    clause_results = []
    for result in filtered_results:
        # ä»æ•°æ®åº“è·å–å®Œæ•´metadata
        doc = get_document_by_chunk_id(result.chunk_id)
        
        clause_results.append(ClauseResult(
            chunk_id=result.chunk_id,
            content=result.content,
            section_id=result.metadata.get("section_id", ""),
            section_title=result.metadata.get("section_title", ""),
            similarity_score=result.similarity_score,
            source_reference={
                "product_name": doc.product.name,
                "document_type": doc.doc_type,
                "pdf_path": doc.local_path,
                "page_number": result.metadata.get("page_number"),
                "download_url": doc.url
            }
        ))
    
    return clause_results

# MCP Toolå®šä¹‰
search_policy_clause_tool = Tool(
    name="search_policy_clause",
    description="æœç´¢ä¿é™©æ¡æ¬¾ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢å’Œç²¾ç¡®è¿‡æ»¤",
    inputSchema=SearchPolicyClauseInput.schema()
)
```

**å®ç°ç¤ºä¾‹ - Tool 2: check_exclusion_risk**

```python
# check_exclusion.py
class CheckExclusionRiskInput(BaseModel):
    scenario_description: str
    product_id: Optional[str] = None
    strict_mode: bool = True

class ExclusionCheckResult(BaseModel):
    is_excluded: bool
    confidence: float
    matched_clauses: List[ClauseResult]
    risk_summary: str
    disclaimer: str = "æœ¬ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…ç†èµ”ä»¥ä¿é™©åˆåŒå’Œå…¬å¸å®¡æ ¸ä¸ºå‡†"

async def check_exclusion_risk(input: CheckExclusionRiskInput) -> ExclusionCheckResult:
    """
    å…è´£æ¡æ¬¾æ ¸æŸ¥å·¥å…·
    
    ä¸“é—¨æ£€ç´¢å…è´£æ¡æ¬¾ï¼Œåˆ¤æ–­ç‰¹å®šåœºæ™¯æ˜¯å¦è¢«æ’é™¤
    """
    # 1. å…³é”®è¯æ‰©å±•ï¼ˆå¢å¼ºå¬å›ç‡ï¼‰
    expanded_query = expand_exclusion_keywords(input.scenario_description)
    # ä¾‹å¦‚: "é…’é©¾" -> ["é…’åé©¾é©¶", "é¥®é…’", "é†‰é…’", "é…’ç²¾å½±å“"]
    
    # 2. å¼ºåˆ¶è¿‡æ»¤category="Exclusion"
    results = await search_policy_clause(SearchPolicyClauseInput(
        query=expanded_query,
        product_id=input.product_id,
        category="Exclusion",
        top_k=10
    ))
    
    # 3. åˆ¤æ–­æ˜¯å¦æ˜ç¡®å…è´£
    is_excluded = False
    confidence = 0.0
    
    if results:
        # ä½¿ç”¨LLMè¿›è¡ŒäºŒæ¬¡åˆ¤æ–­ï¼ˆå¯é€‰ï¼‰
        is_excluded, confidence = await llm_judge_exclusion(
            scenario=input.scenario_description,
            clauses=[r.content for r in results]
        )
    
    # 4. ç”Ÿæˆé£é™©æ€»ç»“
    risk_summary = generate_risk_summary(
        is_excluded=is_excluded,
        matched_clauses=results
    )
    
    return ExclusionCheckResult(
        is_excluded=is_excluded,
        confidence=confidence,
        matched_clauses=results,
        risk_summary=risk_summary
    )

def expand_exclusion_keywords(scenario: str) -> str:
    """æ‰©å±•å…è´£åœºæ™¯çš„å…³é”®è¯"""
    keyword_map = {
        "é…’é©¾": ["é…’åé©¾é©¶", "é¥®é…’", "é†‰é…’", "é…’ç²¾"],
        "å¸æ¯’": ["æ¯’å“", "å¸é£Ÿæ¯’å“", "æ³¨å°„æ¯’å“", "éº»é†‰è¯å“"],
        "è‡ªæ€": ["è‡ªæ€", "è‡ªæ®‹", "è‡ªä¼¤"],
        # ... æ›´å¤šæ˜ å°„
    }
    
    for key, expansions in keyword_map.items():
        if key in scenario:
            return " OR ".join(expansions)
    
    return scenario
```

**å®ç°ç¤ºä¾‹ - Tool 3: calculate_surrender_value_logic**

```python
# surrender_logic.py
class CalculateSurrenderValueLogicInput(BaseModel):
    product_id: str
    policy_year: Optional[int] = None
    operation: str  # "surrender" æˆ– "reduced_paid_up"

class SurrenderLogicResult(BaseModel):
    operation_name: str
    definition: str
    calculation_rules: List[str]
    conditions: List[str]
    consequences: List[str]
    related_tables: List[dict]
    comparison_note: str
    source_references: List[dict]

async def calculate_surrender_value_logic(
    input: CalculateSurrenderValueLogicInput
) -> SurrenderLogicResult:
    """
    é€€ä¿/å‡é¢äº¤æ¸…é€»è¾‘æå–å·¥å…·
    
    åŒæ—¶è¿”å›é€€ä¿å’Œå‡é¢äº¤æ¸…çš„æ¡æ¬¾ï¼Œä¾¿äºå¯¹æ¯”
    """
    # 1. æ£€ç´¢é€€ä¿æ¡æ¬¾
    surrender_clauses = await search_policy_clause(SearchPolicyClauseInput(
        query="é€€ä¿ ç°é‡‘ä»·å€¼",
        product_id=input.product_id,
        category="Process",
        top_k=3
    ))
    
    # 2. æ£€ç´¢å‡é¢äº¤æ¸…æ¡æ¬¾
    reduced_clauses = await search_policy_clause(SearchPolicyClauseInput(
        query="å‡é¢äº¤æ¸…",
        product_id=input.product_id,
        category="Process",
        top_k=3
    ))
    
    # 3. æ£€ç´¢ç›¸å…³è¡¨æ ¼
    table_chunks = await search_table_chunks(
        product_id=input.product_id,
        table_types=["ç°é‡‘ä»·å€¼è¡¨", "å‡é¢äº¤æ¸…å¯¹æ¯”è¡¨"]
    )
    
    # 4. æå–ç»“æ„åŒ–ä¿¡æ¯
    operation_name = "é€€ä¿" if input.operation == "surrender" else "å‡é¢äº¤æ¸…"
    
    definition = extract_definition(
        surrender_clauses if input.operation == "surrender" else reduced_clauses
    )
    
    calculation_rules = extract_calculation_rules(definition)
    conditions = extract_conditions(definition)
    consequences = extract_consequences(definition)
    
    # 5. ç”Ÿæˆå¯¹æ¯”è¯´æ˜
    comparison_note = (
        "é€€ä¿ï¼šä¸€æ¬¡æ€§æ‹¿å›ç°é‡‘ä»·å€¼ï¼Œä½†å¤±å»ä¿éšœã€‚\n"
        "å‡é¢äº¤æ¸…ï¼šä¸æ‹¿é’±ã€ä¸äº¤é’±ï¼Œä¿éšœç¼©æ°´ä½†åˆåŒç»§ç»­æœ‰æ•ˆã€‚"
    )
    
    # 6. æ·»åŠ ç¼ºå¤±æç¤º
    if not any("ç°é‡‘ä»·å€¼è¡¨" in t["type"] for t in table_chunks):
        calculation_rules.append(
            "âš ï¸ å…·ä½“é‡‘é¢éœ€æŸ¥é˜…ä¿å•é™„å¸¦çš„ç°é‡‘ä»·å€¼è¡¨"
        )
    
    return SurrenderLogicResult(
        operation_name=operation_name,
        definition=definition,
        calculation_rules=calculation_rules,
        conditions=conditions,
        consequences=consequences,
        related_tables=table_chunks,
        comparison_note=comparison_note,
        source_references=[c.source_reference for c in surrender_clauses + reduced_clauses]
    )
```

**MCP Serveré›†æˆ**:
```python
# server.py
from mcp.server.stdio import stdio_server
from src.mcp_server.tools import (
    search_policy_clause_tool,
    check_exclusion_risk_tool,
    calculate_surrender_value_logic_tool
)

app = Server("insurance-mcp")

# æ³¨å†Œå·¥å…·
@app.list_tools()
async def list_tools():
    return [
        search_policy_clause_tool,
        check_exclusion_risk_tool,
        calculate_surrender_value_logic_tool
    ]

@app.call_tool()
async def call_tool(name: str, arguments: dict):
    if name == "search_policy_clause":
        return await search_policy_clause(SearchPolicyClauseInput(**arguments))
    elif name == "check_exclusion_risk":
        return await check_exclusion_risk(CheckExclusionRiskInput(**arguments))
    elif name == "calculate_surrender_value_logic":
        return await calculate_surrender_value_logic(CalculateSurrenderValueLogicInput(**arguments))
    else:
        raise ValueError(f"Unknown tool: {name}")
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] 3ä¸ªå·¥å…·éƒ½èƒ½æ­£ç¡®å“åº”å¹¶è¿”å›ç»“æ„åŒ–ç»“æœ
- [ ] `check_exclusion_risk` çš„å…è´£æ¡æ¬¾å¬å›ç‡ > 95%
- [ ] `calculate_surrender_value_logic` èƒ½åŒæ—¶è¿”å›é€€ä¿å’Œå‡é¢äº¤æ¸…ä¿¡æ¯
- [ ] æ‰€æœ‰å·¥å…·è¿”å›ç»“æœéƒ½åŒ…å«å®Œæ•´çš„ `source_reference`

**ä¾èµ–**:
- ä¾èµ– T022aï¼ˆæ··åˆæ£€ç´¢ï¼‰
- ä¾èµ– T023aï¼ˆè¡¨æ ¼å¤„ç†ï¼‰
- ä¾èµ– T023ï¼ˆChromaDBç´¢å¼•ï¼‰

---

### T028a [US1] é»„é‡‘æµ‹è¯•é›†æ„å»º

**ä¼˜å…ˆçº§**: P1 (MEDIUM - è´¨é‡ä¿è¯)

**ç›®æ ‡**: æ„å»ºåŒ…å«50ä¸ªæ ‡å‡†ä¿é™©é—®é¢˜çš„é»„é‡‘æµ‹è¯•é›†ï¼Œç”¨äºæŒç»­è¯„ä¼°æ£€ç´¢è´¨é‡ã€‚

**æ–‡ä»¶**: `tests/golden_dataset/insurance_qa_golden.json`

**æ•°æ®ç»“æ„**:
```json
{
  "version": "1.0",
  "created_at": "2025-11-21",
  "total_questions": 50,
  "categories": {
    "basic": 20,
    "comparison": 15,
    "exclusion": 15
  },
  "questions": [
    {
      "id": "Q001",
      "category": "basic",
      "question": "å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©çš„ä¿é™©æœŸé—´æ˜¯å¤šä¹…ï¼Ÿ",
      "ground_truth": {
        "section_id": "1.4",
        "section_title": "ä¿é™©æœŸé—´",
        "expected_keywords": ["ä¿é™©æœŸé—´", "åˆåŒç”Ÿæ•ˆä¹‹æ—¥", "ä¿é™©æœŸæ»¡"],
        "product_name": "å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©ï¼ˆåˆ†çº¢å‹ï¼‰"
      },
      "acceptance_criteria": {
        "must_appear_in_top": 1,
        "min_similarity_score": 0.85
      }
    },
    {
      "id": "Q015",
      "category": "comparison",
      "question": "å‡é¢äº¤æ¸…å’Œé€€ä¿æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿå“ªä¸ªæ›´åˆ’ç®—ï¼Ÿ",
      "ground_truth": {
        "section_ids": ["6.4", "5.2"],
        "section_titles": ["å‡é¢äº¤æ¸…", "é€€ä¿"],
        "expected_keywords": ["å‡é¢äº¤æ¸…", "é€€ä¿", "ç°é‡‘ä»·å€¼", "ä¿é¢å‡å°‘"],
        "product_name": "å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©ï¼ˆåˆ†çº¢å‹ï¼‰"
      },
      "acceptance_criteria": {
        "must_appear_in_top": 3,
        "all_sections_present": true,
        "min_similarity_score": 0.75
      }
    },
    {
      "id": "Q030",
      "category": "exclusion",
      "question": "å¦‚æœè¢«ä¿é™©äººé…’åé©¾é©¶æ‘©æ‰˜è½¦å‡ºäº‹ï¼Œä¿é™©å…¬å¸èµ”å—ï¼Ÿ",
      "ground_truth": {
        "section_id": "2.1",
        "section_title": "è´£ä»»å…é™¤",
        "expected_keywords": ["é…’åé©¾é©¶", "é†‰é…’", "é¥®é…’", "å…è´£"],
        "is_exclusion": true,
        "product_name": "å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©ï¼ˆåˆ†çº¢å‹ï¼‰"
      },
      "acceptance_criteria": {
        "must_appear_in_top": 1,
        "category_filter": "Exclusion",
        "min_similarity_score": 0.90
      }
    }
  ]
}
```

**æµ‹è¯•è„šæœ¬**:
```python
# tests/golden_dataset/test_retrieval_quality.py
import json
import pytest
from src.mcp_server.tools.search_clause import search_policy_clause

class TestGoldenDataset:
    @pytest.fixture
    def golden_data(self):
        with open("tests/golden_dataset/insurance_qa_golden.json") as f:
            return json.load(f)
    
    @pytest.mark.asyncio
    async def test_basic_queries(self, golden_data):
        """æµ‹è¯•åŸºç¡€æŸ¥è¯¢ç±»é—®é¢˜"""
        basic_questions = [q for q in golden_data["questions"] if q["category"] == "basic"]
        
        passed = 0
        for q in basic_questions:
            results = await search_policy_clause(SearchPolicyClauseInput(
                query=q["question"],
                product=q["ground_truth"]["product_name"],
                top_k=5
            ))
            
            # æ£€æŸ¥ground truthæ˜¯å¦åœ¨top-1
            if results and results[0].section_id == q["ground_truth"]["section_id"]:
                passed += 1
            
            # æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼
            if results and results[0].similarity_score >= q["acceptance_criteria"]["min_similarity_score"]:
                passed += 0.5  # éƒ¨åˆ†åˆ†
        
        accuracy = passed / len(basic_questions)
        assert accuracy >= 0.90, f"Basic query accuracy {accuracy} < 0.90"
    
    @pytest.mark.asyncio
    async def test_comparison_queries(self, golden_data):
        """æµ‹è¯•å¯¹æ¯”æŸ¥è¯¢ç±»é—®é¢˜"""
        comparison_questions = [q for q in golden_data["questions"] if q["category"] == "comparison"]
        
        passed = 0
        for q in comparison_questions:
            results = await search_policy_clause(SearchPolicyClauseInput(
                query=q["question"],
                product=q["ground_truth"]["product_name"],
                top_k=5
            ))
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰ç›¸å…³section
            returned_sections = {r.section_id for r in results[:3]}
            expected_sections = set(q["ground_truth"]["section_ids"])
            
            if expected_sections.issubset(returned_sections):
                passed += 1
        
        accuracy = passed / len(comparison_questions)
        assert accuracy >= 0.85, f"Comparison query accuracy {accuracy} < 0.85"
    
    @pytest.mark.asyncio
    async def test_exclusion_queries(self, golden_data):
        """æµ‹è¯•å…è´£æ¡æ¬¾æŸ¥è¯¢"""
        exclusion_questions = [q for q in golden_data["questions"] if q["category"] == "exclusion"]
        
        passed = 0
        for q in exclusion_questions:
            results = await search_policy_clause(SearchPolicyClauseInput(
                query=q["question"],
                product=q["ground_truth"]["product_name"],
                category="Exclusion",
                top_k=5
            ))
            
            # æ£€æŸ¥è¿”å›çš„éƒ½æ˜¯å…è´£æ¡æ¬¾
            all_exclusion = all(r.metadata["category"] == "Exclusion" for r in results)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ground truth
            contains_truth = any(r.section_id == q["ground_truth"]["section_id"] for r in results)
            
            if all_exclusion and contains_truth:
                passed += 1
        
        recall = passed / len(exclusion_questions)
        assert recall >= 0.95, f"Exclusion recall {recall} < 0.95"
```

**é»„é‡‘æ•°æ®é›†æ„å»ºæµç¨‹**:

1. **åˆå§‹ç§å­é—®é¢˜**ï¼ˆäººå·¥ç¼–å†™ï¼‰ï¼š
   - ä»å¹³å®‰ç¦è€€å¹´é‡‘ä¿é™©æ¡æ¬¾ä¸­æå–20ä¸ªå…¸å‹é—®é¢˜
   - æ¶µç›–ä¿é™©æœŸé—´ã€ä¿é™©é‡‘ã€å…è´£ã€é€€ä¿ç­‰æ ¸å¿ƒä¸»é¢˜

2. **é—®é¢˜æ‰©å±•**ï¼ˆåŠè‡ªåŠ¨ï¼‰ï¼š
   - ä½¿ç”¨LLMç”Ÿæˆå˜ä½“é—®é¢˜ï¼ˆæ”¹å†™ã€åŒä¹‰æ›¿æ¢ï¼‰
   - äººå·¥å®¡æ ¸å¹¶æ ‡æ³¨æ­£ç¡®ç­”æ¡ˆ

3. **çœŸå®ç”¨æˆ·é—®é¢˜æ”¶é›†**ï¼ˆæœªæ¥ï¼‰ï¼š
   - ä»MCPæœåŠ¡å™¨æ—¥å¿—ä¸­æ”¶é›†çœŸå®æŸ¥è¯¢
   - äººå·¥æ ‡æ³¨å¹¶è¡¥å……åˆ°é»„é‡‘é›†

**éªŒæ”¶æ ‡å‡†**:
- [ ] é»„é‡‘æµ‹è¯•é›†åŒ…å« â‰¥ 50ä¸ªé—®é¢˜
- [ ] åŸºç¡€æŸ¥è¯¢å‡†ç¡®ç‡ â‰¥ 90%
- [ ] å¯¹æ¯”æŸ¥è¯¢å‡†ç¡®ç‡ â‰¥ 85%
- [ ] å…è´£æŸ¥è¯¢å¬å›ç‡ â‰¥ 95%
- [ ] æ¯æœˆè¿è¡Œä¸€æ¬¡ï¼Œè®°å½•è¶‹åŠ¿

**ä¾èµ–**:
- ä¾èµ–æ‰€æœ‰å‰ç½®ä»»åŠ¡ï¼ˆT020a ~ T025aï¼‰
- ç”¨äºæŒç»­è´¨é‡ç›‘æ§

---

## ä»»åŠ¡ä¾èµ–å…³ç³»å›¾ï¼ˆæ›´æ–°ï¼‰

```mermaid
graph TD
    T019[T019 å®¡æ ¸å‘˜CLI] --> T020a[T020a Markdownåå¤„ç†]
    T020a --> T021[T021 Embedding]
    T020a --> T022a[T022a æ··åˆæ£€ç´¢]
    T020a --> T023a[T023a è¡¨æ ¼ç‹¬ç«‹Chunk]
    
    T021 --> T022[T022 ChromaDB]
    T022a --> T023[T023 ç´¢å¼•å™¨]
    T022 --> T023
    T023a --> T023
    
    T023 --> T025a[T025a é‡æ–°è®¾è®¡MCPå·¥å…·]
    T022a --> T025a
    
    T025a --> T028a[T028a é»„é‡‘æµ‹è¯•é›†]
    
    T028a --> T031[T031 ç«¯åˆ°ç«¯æµ‹è¯•]
```

---

## CLIå‘½ä»¤æ›´æ–°å»ºè®®

```bash
# æ·»åŠ åˆ° src/cli/manage.py

# åå¤„ç†å‘½ä»¤ç»„
python -m src.cli.manage process postprocess --doc-id <id>  # T020a
python -m src.cli.manage process postprocess --all          # T020a

# ç´¢å¼•å‘½ä»¤ï¼ˆæ‰©å±•ï¼‰
python -m src.cli.manage index --rebuild --enable-bm25      # T022a
python -m src.cli.manage index test-search "<query>" --method hybrid  # T022a

# æµ‹è¯•å‘½ä»¤ç»„
python -m src.cli.manage test golden --category basic       # T028a
python -m src.cli.manage test golden --category comparison  # T028a
python -m src.cli.manage test golden --category exclusion   # T028a
python -m src.cli.manage test golden --all --report         # T028a
```

---

## å®æ–½æ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹ç¬¬äº”é˜¶æ®µå®æ–½å‰ï¼Œç¡®è®¤ä»¥ä¸‹å‡†å¤‡å·¥ä½œï¼š

- [ ] å·²å®Œæˆç¬¬å››é˜¶æ®µæ‰€æœ‰ä»»åŠ¡ï¼ˆT015-T019ï¼‰
- [ ] å·²æœ‰ â‰¥ 20ä»½ VERIFIED çŠ¶æ€çš„æ–‡æ¡£
- [ ] Pythonç¯å¢ƒå·²å®‰è£…æ–°ä¾èµ–ï¼š`rank-bm25`, `jieba`, `langchain`
- [ ] å·²é˜…è¯»å¹¶ç†è§£ç”¨æˆ·æä¾›çš„ä¼˜åŒ–å»ºè®®
- [ ] spec.md å·²æ›´æ–°ï¼ˆåº”ç”¨ SPEC_OPTIMIZATION_PATCH.mdï¼‰
- [ ] data-model.md å·²æ›´æ–°ï¼ˆåº”ç”¨ DATA_MODEL_PATCH.mdï¼‰
- [ ] å›¢é˜Ÿå·²å¯¹æ–°çš„MCPå·¥å…·è®¾è®¡è¾¾æˆå…±è¯†

---

**ä»»åŠ¡æ‰©å±•å®Œæˆã€‚é¢„è®¡æ–°å¢å·¥ä½œé‡ï¼š15-20å·¥ä½œæ—¥ã€‚**

